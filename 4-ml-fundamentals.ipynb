{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Engineer Roadmap\n",
    "## ML Fundamentals\n",
    "### https://zazencodes.com/courses/ai-engineer-roadmap#ml-fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Price: $340,000.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Training data: square footage and bedrooms (input) and price (output)\n",
    "X = np.array([[1200, 2], [1500, 3], [1800, 3], [2000, 4]])  # Square footage, bedrooms\n",
    "y = np.array([240000, 300000, 360000, 400000])  # Prices\n",
    "\n",
    "# Create and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict the price of a 1700 sqft house with 3 bedrooms\n",
    "predicted_price = model.predict([[1700, 3]])\n",
    "print(f\"Predicted Price: ${predicted_price[0]:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email Classification: normal\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Training data: [email_length, contains_urgent, contains_money]\n",
    "X = np.array([\n",
    "    [100, 0, 0],  # Normal email\n",
    "    [850, 1, 1],  # Spam email\n",
    "    [300, 0, 0],  # Normal email\n",
    "    [600, 1, 1],  # Spam email\n",
    "    [400, 0, 0],  # Normal email\n",
    "])\n",
    "y = np.array(['normal', 'spam', 'normal', 'spam', 'normal'])  # Labels\n",
    "\n",
    "# Create and train the model\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X, y)\n",
    "\n",
    "# Predict if a new email is spam\n",
    "new_email = [[500, 1, 1]]  # Length: 500, contains \"urgent\" and \"money\"\n",
    "prediction = classifier.predict(new_email)\n",
    "print(f\"Email Classification: {prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster assignments: [0 1 0 1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Customer data (standardized): [annual income, spending score, loyalty years]\n",
    "data = np.array([\n",
    "    [0.0, 0.42, 0.17], [0.13, 0.95, 0.67], [0.25, 0.0, 0.0], [0.38, 0.90, 0.50], [0.50, 0.43, 0.33],\n",
    "    [0.63, 0.89, 0.83], [0.75, 0.05, 0.17], [0.88, 1.0, 1.0], [1.0, 0.37, 0.33]\n",
    "])\n",
    "\n",
    "# Create and train the model\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(data)\n",
    "\n",
    "# Assign clusters to customers\n",
    "clusters = kmeans.labels_\n",
    "print(f\"Cluster assignments: {clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: left, Reward: -1\n",
      "Action: up, Reward: 0\n",
      "Action: down, Reward: -1\n",
      "Action: left, Reward: -1\n",
      "Action: up, Reward: 0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define environment and rewards\n",
    "actions = [\"left\", \"right\", \"up\", \"down\"]\n",
    "rewards = {\"left\": -1, \"right\": 1, \"up\": 0, \"down\": -1}\n",
    "\n",
    "# Simulate an agent taking random actions\n",
    "for _ in range(5):  # Five moves\n",
    "    action = random.choice(actions)\n",
    "    reward = rewards[action]\n",
    "    print(f\"Action: {action}, Reward: {reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Spam\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Training data: [email_length, contains_urgent, contains_money]\n",
    "X = np.array([\n",
    "    [100, 0, 0],  # Normal email\n",
    "    [850, 1, 1],  # Spam email\n",
    "    [300, 0, 0],  # Normal email\n",
    "    [600, 1, 1],  # Spam email\n",
    "    [400, 0, 0],  # Normal email\n",
    "])\n",
    "y = np.array([0, 1, 0, 1, 0]) # Spam (1) or Not Spam (0)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict spam for a new email with feature values [500, 0, 0]\n",
    "prediction = model.predict([[500, 0, 0]])\n",
    "print(\"Spam\" if prediction[0] == 1 else \"Not Spam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legitimate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/pro/ai-engineer-roadmap/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [09:23:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Training data: [transaction amount, number of transactions, time since last transaction]\n",
    "X = np.array([[100, 10, 24], [200, 15, 48], [50, 5, 1], [300, 20, 72]])\n",
    "y = np.array([0, 0, 1, 1])  # Fraudulent (1) or Legitimate (0)\n",
    "\n",
    "# Train the model\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict fraud for a transaction with amount=150, transactions=12, time=36\n",
    "prediction = model.predict([[150, 12, 36]])\n",
    "print(\"Fraudulent\" if prediction[0] == 1 else \"Legitimate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name   Age   Salary\n",
      "0  Alice  25.0  50000.0\n",
      "3  David  22.0  52000.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "       'Age': [25, None, 30, 22],\n",
    "       'Salary': [50000, 60000, None, 52000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_cleaned = df.dropna()\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name        Age   Salary\n",
      "0    Alice  25.000000  50000.0\n",
      "1      Bob  25.666667  60000.0\n",
      "2  Charlie  30.000000  52000.0\n",
      "3    David  22.000000  52000.0\n"
     ]
    }
   ],
   "source": [
    "# Fill missing Age with the mean\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "# Fill missing Salary with the median\n",
    "df['Salary'] = df['Salary'].fillna(df['Salary'].median())\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = [1, 2, 2, 3, 3, 4, 100, 2, 3, 4, 2, 1000]\n",
    "\n",
    "# Calculate Z-scores\n",
    "mean = np.mean(data)\n",
    "std_dev = np.std(data)\n",
    "z_scores = [(x - mean) / std_dev for x in data]\n",
    "\n",
    "# Identify outliers with |Z-score| > 3\n",
    "outliers = [x for x, z in zip(data, z_scores) if abs(z) > 3]\n",
    "print(outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:               [1, 2, 2, 3, 3, 4, 100, 2, 3, 4, 2, 1000]\n",
      "After removing outliers:     [1, 2, 2, 3, 3, 4, 100, 2, 3, 4, 2]\n",
      "After capping outliers:      [1.11, 2, 2, 3, 3, 4, 100, 2, 3, 4, 2, 901.0000000000005]\n",
      "After replacing with median: [1, 2, 2, 3, 3, 4, 3.0, 2, 3, 4, 2, 3.0]\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers_zscore(data, threshold=3):\n",
    "    z_scores = np.abs((data - np.mean(data)) / np.std(data))\n",
    "    return [x for x, z in zip(data, z_scores) if z < threshold]\n",
    "\n",
    "# Cap outliers using percentiles (Winsorization)\n",
    "def cap_outliers(data, lower_percentile=1, upper_percentile=99):\n",
    "    lower = np.percentile(data, lower_percentile)\n",
    "    upper = np.percentile(data, upper_percentile)\n",
    "    return [min(max(x, lower), upper) for x in data]\n",
    "\n",
    "# Replace with median for extreme values\n",
    "def replace_with_median(data, threshold=3):\n",
    "    median = np.median(data)\n",
    "    mad = np.median(np.abs(data - median))\n",
    "    modified = [median if abs((x - median) / mad) > threshold else x for x in data]\n",
    "    return modified\n",
    "\n",
    "# Apply different methods\n",
    "cleaned_zscore = remove_outliers_zscore(data)\n",
    "capped_data = cap_outliers(data)\n",
    "median_replaced = replace_with_median(data)\n",
    "\n",
    "print(\"Original data:              \", data)\n",
    "print(\"After removing outliers:    \", cleaned_zscore)\n",
    "print(\"After capping outliers:     \", capped_data)\n",
    "print(\"After replacing with median:\", median_replaced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      " [   1    2    3  100    2    3 1000]\n",
      "\n",
      "Robust scaled:\n",
      " [-0.04040404 -0.02020202  0.          1.95959596 -0.02020202  0.\n",
      " 20.14141414]\n",
      "\n",
      "Log transformed:\n",
      " [0.69314718 1.09861229 1.38629436 4.61512052 1.09861229 1.38629436\n",
      " 6.90875478]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Sample data with outliers\n",
    "data = np.array([1, 2, 3, 100, 2, 3, 1000]).reshape(-1, 1)\n",
    "\n",
    "# Apply robust scaling\n",
    "robust_scaler = RobustScaler()\n",
    "scaled_data = robust_scaler.fit_transform(data)\n",
    "\n",
    "# Apply log transformation (adding 1 to handle zeros)\n",
    "log_data = np.log1p(data)\n",
    "\n",
    "print(\"Original data:\\n\", data.ravel())\n",
    "print()\n",
    "print(\"Robust scaled:\\n\", scaled_data.ravel())\n",
    "print()\n",
    "print(\"Log transformed:\\n\", log_data.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  ]\n",
      " [0.25]\n",
      " [0.5 ]\n",
      " [0.75]\n",
      " [1.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = [[1], [2], [3], [4], [5]]\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "print(scaled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.41421356]\n",
      " [-0.70710678]\n",
      " [ 0.        ]\n",
      " [ 0.70710678]\n",
      " [ 1.41421356]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = [[10], [20], [30], [40], [50]]\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(data)\n",
    "print(standardized_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.05882353]\n",
      " [-0.01960784]\n",
      " [ 0.01960784]\n",
      " [ 3.82352941]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "data = [[1], [2], [3], [100]]  # Outlier included\n",
    "scaler = RobustScaler()\n",
    "robust_scaled_data = scaler.fit_transform(data)\n",
    "print(robust_scaled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello world', 'helloworld', 'hello world', 'hello world']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample text data\n",
    "text_data = [\" Hello World! \", \"Hello@#$World\", \"hello   world\", \"HELLO WORLD\"]\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Clean the text data\n",
    "cleaned_text = [clean_text(text) for text in text_data]\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample sentence common english words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n",
    "def process_text(text):\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Join tokens back\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Example usage\n",
    "text = \"This is a sample sentence with some common English words\"\n",
    "processed_text = process_text(text)\n",
    "print(processed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   values  parsed_values\n",
      "0   1,234       1234.000\n",
      "1  $5,000       5000.000\n",
      "2   42.5%          0.425\n",
      "3     N/A            NaN\n",
      "4    1.5M    1500000.000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data with mixed number formats\n",
    "data = {\n",
    "    'values': ['1,234', '$5,000', '42.5%', 'N/A', '1.5M']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def parse_numbers(value):\n",
    "    try:\n",
    "        # Remove currency symbols and commas\n",
    "        value = str(value).replace('$', '').replace(',', '')\n",
    "        # Handle percentages\n",
    "        if '%' in value:\n",
    "            return float(value.replace('%', '')) / 100\n",
    "        # Handle millions\n",
    "        if 'M' in value:\n",
    "            return float(value.replace('M', '')) * 1_000_000\n",
    "        # Convert to float\n",
    "        return float(value)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Apply parsing\n",
    "df['parsed_values'] = df['values'].apply(parse_numbers)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          dates parsed_dates custom_parsed_dates\n",
      "0    2023-01-01   2023-01-01          2023-01-01\n",
      "1    01/15/2023   2023-01-15          2023-01-15\n",
      "2  Jan 20, 2023   2023-01-20          2023-01-20\n",
      "3    2023.02.01   2023-02-01          2023-02-01\n",
      "4      20230301   2023-03-01          2023-03-01\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data with different date formats\n",
    "dates = {\n",
    "    'dates': [\n",
    "        '2023-01-01',\n",
    "        '01/15/2023',\n",
    "        'Jan 20, 2023',\n",
    "        '2023.02.01',\n",
    "        '20230301'\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(dates)\n",
    "\n",
    "# Parse dates using pandas\n",
    "df['parsed_dates'] = pd.to_datetime(df['dates'], format='mixed')\n",
    "\n",
    "# Custom date parsing function for specific formats\n",
    "def parse_custom_date(date_str):\n",
    "    formats = [\n",
    "        '%Y-%m-%d',\n",
    "        '%m/%d/%Y',\n",
    "        '%b %d, %Y',\n",
    "        '%Y.%m.%d',\n",
    "        '%Y%m%d'\n",
    "    ]\n",
    "\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "# Apply custom parsing\n",
    "df['custom_parsed_dates'] = df['dates'].apply(parse_custom_date)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Height  Weight        BMI\n",
      "0     170      70  24.221453\n",
      "1     165      60  22.038567\n",
      "2     180      80  24.691358\n"
     ]
    }
   ],
   "source": [
    " import pandas as pd\n",
    "\n",
    " # Sample DataFrame\n",
    " data = {'Height': [170, 165, 180], 'Weight': [70, 60, 80]}\n",
    " df = pd.DataFrame(data)\n",
    "\n",
    " # Create a new feature: BMI (Body Mass Index)\n",
    " df['BMI'] = df['Weight'] / (df['Height'] / 100) ** 2\n",
    " print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Height  Weight        BMI       Date Day_of_Week\n",
      "0     170      70  24.221453 2024-01-01      Monday\n",
      "1     165      60  22.038567 2024-01-02     Tuesday\n",
      "2     180      80  24.691358 2024-01-03   Wednesday\n"
     ]
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(['2024-01-01', '2024-01-02', '2024-01-03'])\n",
    "df['Day_of_Week'] = df['Date'].dt.day_name()\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Height  Weight        BMI       Date Day_of_Week                Review  \\\n",
      "0     170      70  24.221453 2024-01-01      Monday        Great product!   \n",
      "1     165      60  22.038567 2024-01-02     Tuesday               Not bad   \n",
      "2     180      80  24.691358 2024-01-03   Wednesday  Terrible experience.   \n",
      "\n",
      "   Review_Length  \n",
      "0             14  \n",
      "1              7  \n",
      "2             20  \n"
     ]
    }
   ],
   "source": [
    "df['Review'] = ['Great product!', 'Not bad', 'Terrible experience.']\n",
    "df['Review_Length'] = df['Review'].apply(len)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12609839 0.03224898 0.38591743 0.4557352 ]\n"
     ]
    }
   ],
   "source": [
    "# Random Forests provide feature importance scores based on how much\n",
    "# each feature contributes to decreasing impurity across all trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load sample iris dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Initialize and train the random forest\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get feature importance scores - higher scores mean more important features\n",
    "print(model.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/pro/zazencodes-courses/ai-engineer-roadmap/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination (RFE) iteratively removes features\n",
    "# by training the model multiple times and eliminating the weakest feature\n",
    "# until the desired number of features is reached\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Create RFE selector that will select 2 best features\n",
    "rfe = RFE(model, n_features_to_select=2)\n",
    "\n",
    "# Fit RFE - this will iteratively eliminate features\n",
    "rfe = rfe.fit(X, y)\n",
    "\n",
    "# Print boolean mask of selected features (True = selected)\n",
    "print(rfe.support_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features shape: (150, 4)\n",
      "Selected features shape: (150, 2)\n",
      "Feature scores: [ 119.26450218   49.16004009 1180.16118225  960.0071468 ]\n",
      "Selected features: [False False  True  True]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Create a selector that will keep the 2 best features\n",
    "# f_classif measures the relationship between each feature and the target variable\n",
    "selector = SelectKBest(score_func=f_classif, k=2)\n",
    "\n",
    "# Fit the selector and transform the data\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "print(\"Original features shape:\", X.shape)\n",
    "print(\"Selected features shape:\", X_selected.shape)\n",
    "print(\"Feature scores:\", selector.scores_)\n",
    "print(\"Selected features:\", selector.get_support())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.68412563  0.31939725]\n",
      " [-2.71414169 -0.17700123]\n",
      " [-2.88899057 -0.14494943]\n",
      " [-2.74534286 -0.31829898]\n",
      " [-2.72871654  0.32675451]]\n",
      "Explained variance ratio: [0.92461872 0.05306648]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(X_pca[:5])\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.91274714 -2.30203322]\n",
      " [ 5.57248242 -1.97182599]\n",
      " [ 5.44697714 -2.09520636]\n",
      " [ 5.43645948 -1.87038151]\n",
      " [ 5.87564494 -2.32829018]]\n",
      "Explained variance ratio: [0.52875361 0.44845576]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "X_svd = svd.fit_transform(X)\n",
    "print(X_svd[:5])\n",
    "print(\"Explained variance ratio:\", svd.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-26.62385    -2.969567 ]\n",
      " [-29.334204   -2.056246 ]\n",
      " [-29.084578   -3.2681649]\n",
      " [-29.577831   -2.9022093]\n",
      " [-26.578043   -3.3951583]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "print(X_tsne[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 105\n",
      "Testing set size: 22\n",
      "Evaluation set size: 23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# First split: training (70%) vs test+eval (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: test (15%) and eval (15%) from the temp set\n",
    "X_test, X_eval, y_test, y_eval = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Testing set size:\", len(X_test))\n",
    "print(\"Evaluation set size:\", len(X_eval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Accuracy: 1.0\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model = LogisticRegression()\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 1.0\n",
      "Accuracy: 0.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/pro/zazencodes-courses/ai-engineer-roadmap/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize stratified k-fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Perform stratified k-fold cross validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "Training set size: 25, Test set size: 25\n",
      "MSE: 0.0\n",
      "\n",
      "Fold 2:\n",
      "Training set size: 50, Test set size: 25\n",
      "MSE: 1.0\n",
      "\n",
      "Fold 3:\n",
      "Training set size: 75, Test set size: 25\n",
      "MSE: 0.018868056956335345\n",
      "\n",
      "Fold 4:\n",
      "Training set size: 100, Test set size: 25\n",
      "MSE: 0.3483620695449156\n",
      "\n",
      "Fold 5:\n",
      "Training set size: 125, Test set size: 25\n",
      "MSE: 0.12217397712069693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize time series split\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "model = LinearRegression()\n",
    "\n",
    "# Perform time series cross validation\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"Fold {i+1}:\")\n",
    "    print(f\"Training set size: {len(X_train)}, Test set size: {len(X_test)}\")\n",
    "    print(f\"MSE: {mean_squared_error(y_test, predictions)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression with Manual K-Fold Cross-Validation\n",
      "Fold 1 Accuracy: 0.820\n",
      "Fold 2 Accuracy: 0.860\n",
      "Fold 3 Accuracy: 0.810\n",
      "Fold 4 Accuracy: 0.870\n",
      "Fold 5 Accuracy: 0.830\n",
      "\n",
      "Cross-Validation Accuracies: [0.82, 0.86, 0.81, 0.87, 0.83]\n",
      "Mean Accuracy: 0.838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Generate a binary classification dataset\n",
    "X, y = make_classification(n_samples=500, n_features=10, n_informative=5, n_redundant=2, random_state=42)\n",
    "\n",
    "# Initialize K-Fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "\n",
    "print(\"Training Logistic Regression with Manual K-Fold Cross-Validation\")\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X), start=1):\n",
    "    # Split data into training and testing sets for this fold\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions and calculate accuracy\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Fold {fold} Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Final results\n",
    "print(f\"\\nCross-Validation Accuracies: {accuracies}\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracies):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Support Vector Machine (SVM) with Feature Scaling\n",
      "Cross-Validation Accuracies: [0.84 0.87 0.82 0.81 0.85]\n",
      "Mean Accuracy: 0.838\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define a pipeline with scaling and SVM\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize features\n",
    "    ('svm', SVC(kernel='linear', C=1.0))  # Linear Support Vector Machine\n",
    "])\n",
    "\n",
    "# Perform cross-validation\n",
    "print(\"\\nTraining Support Vector Machine (SVM) with Feature Scaling\")\n",
    "scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Results\n",
    "print(f\"Cross-Validation Accuracies: {scores}\")\n",
    "print(f\"Mean Accuracy: {np.mean(scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost with Polynomial Features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/pro/zazencodes-courses/ai-engineer-roadmap/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [20:38:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/alex/pro/zazencodes-courses/ai-engineer-roadmap/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [20:38:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/alex/pro/zazencodes-courses/ai-engineer-roadmap/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [20:38:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/alex/pro/zazencodes-courses/ai-engineer-roadmap/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [20:38:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracies: [0.9  0.92 0.89 0.88 0.91]\n",
      "Mean Accuracy: 0.900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/pro/zazencodes-courses/ai-engineer-roadmap/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [20:38:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create a pipeline with polynomial features and XGBoost\n",
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),  # Add polynomial features\n",
    "    ('scaler', StandardScaler()),  # Standardize features\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))  # XGBoost Classifier\n",
    "])\n",
    "\n",
    "# Perform cross-validation\n",
    "print(\"\\nTraining XGBoost with Polynomial Features\")\n",
    "scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Results\n",
    "print(f\"Cross-Validation Accuracies: {scores}\")\n",
    "print(f\"Mean Accuracy: {np.mean(scores):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.61\n",
      "Precision: 0.58\n",
      "Recall: 0.64\n",
      "F1 Score: 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Example predictions and labels\n",
    "y_true = [0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
    "y_pred = [0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0]\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")    # Proportion of correctly classified samples\n",
    "print(f\"Precision: {precision:.2f}\")  # Fraction of true positives among predicted positives\n",
    "print(f\"Recall: {recall:.2f}\")        # Fraction of true positives among actual positives\n",
    "print(f\"F1 Score: {f1:.2f}\")          # Harmonic mean of precision and recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.19\n",
      "MAE: 0.38\n",
      "R-squared: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Example predictions and labels\n",
    "y_true = [3.0, -0.5, 2.0, 7.0, 1.5, 4.2, -2.1, 8.9, 3.3, 5.7, 2.8, -1.4, 6.1, 0.8, 4.5]\n",
    "y_pred = [2.5, 0.0, 2.0, 8.0, 1.8, 3.9, -1.8, 9.2, 3.0, 5.2, 3.1, -1.0, 5.8, 1.2, 4.8]\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse:.2f}\")      # Average squared difference between predicted and actual values\n",
    "print(f\"MAE: {mae:.2f}\")      # Average absolute difference between predicted and actual values\n",
    "print(f\"R-squared: {r2:.2f}\") # Proportion of variance explained by the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example predictions\n",
    "y_true = [0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
    "y_scores = [0.1, 0.4, 0.35, 0.8, 0.2, 0.7, 0.3, 0.9, 0.15, 0.25, 0.65, 0.75, 0.1, 0.85, 0.2, 0.95, 0.3, 0.6, 0.8, 0.1, 0.67, 0.63, 0.54, 0.0, 0.27, 0.41, 0.67, 0.87, 0.66, 0.98, 0.32, 0.41, 0.02, 0.95, 0.7, 0.81, 0.96, 0.92, 0.27, 0.43]\n",
    "\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "# Plot\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Add diagonal line\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 8\n",
      "False Positives: 3\n",
      "False Negatives: 3\n",
      "True Positives: 11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example predictions and labels\n",
    "y_true = [0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1]\n",
    "y_pred = [0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1]\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                             display_labels=['Negative', 'Positive'])\n",
    "\n",
    "# Plot with customization\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "# Print additional metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"True Negatives: {tn}\")   # Correctly predicted negative cases\n",
    "print(f\"False Positives: {fp}\")  # Incorrectly predicted as positive when actually negative\n",
    "print(f\"False Negatives: {fn}\")  # Incorrectly predicted as negative when actually positive\n",
    "print(f\"True Positives: {tp}\")   # Correctly predicted positive cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "Best Score: 0.9733333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Example dataset\n",
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Define model and hyperparameter grid\n",
    "model = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [3, 5, 8]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Score: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/pro/zazencodes-courses/ai-engineer-roadmap/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-02-27 08:12:03,453] A new study created in memory with name: no-name-a71fcaf9-52ba-43a4-8313-72467436f367\n",
      "[I 2025-02-27 08:12:03,498] Trial 0 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 26, 'max_depth': 29, 'min_samples_split': 2}. Best is trial 0 with value: 0.9466666666666667.\n",
      "[I 2025-02-27 08:12:03,560] Trial 1 finished with value: 0.96 and parameters: {'n_estimators': 39, 'max_depth': 19, 'min_samples_split': 6}. Best is trial 1 with value: 0.96.\n",
      "[I 2025-02-27 08:12:03,717] Trial 2 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 107, 'max_depth': 16, 'min_samples_split': 4}. Best is trial 1 with value: 0.96.\n",
      "[I 2025-02-27 08:12:03,769] Trial 3 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 34, 'max_depth': 9, 'min_samples_split': 9}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:04,003] Trial 4 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 164, 'max_depth': 5, 'min_samples_split': 8}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:04,072] Trial 5 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 45, 'max_depth': 24, 'min_samples_split': 8}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:04,256] Trial 6 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 120, 'max_depth': 8, 'min_samples_split': 6}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:04,464] Trial 7 finished with value: 0.9666666666666667 and parameters: {'n_estimators': 145, 'max_depth': 25, 'min_samples_split': 3}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:04,498] Trial 8 finished with value: 0.9466666666666667 and parameters: {'n_estimators': 20, 'max_depth': 27, 'min_samples_split': 8}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:04,586] Trial 9 finished with value: 0.96 and parameters: {'n_estimators': 59, 'max_depth': 26, 'min_samples_split': 2}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:04,699] Trial 10 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 71, 'max_depth': 11, 'min_samples_split': 10}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:04,866] Trial 11 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 109, 'max_depth': 6, 'min_samples_split': 6}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:05,064] Trial 12 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 132, 'max_depth': 11, 'min_samples_split': 10}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:05,191] Trial 13 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 80, 'max_depth': 11, 'min_samples_split': 5}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:05,467] Trial 14 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 188, 'max_depth': 8, 'min_samples_split': 7}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:05,615] Trial 15 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 96, 'max_depth': 16, 'min_samples_split': 9}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:05,824] Trial 16 finished with value: 0.96 and parameters: {'n_estimators': 138, 'max_depth': 13, 'min_samples_split': 5}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:06,005] Trial 17 finished with value: 0.96 and parameters: {'n_estimators': 121, 'max_depth': 20, 'min_samples_split': 7}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:06,030] Trial 18 finished with value: 0.9533333333333333 and parameters: {'n_estimators': 10, 'max_depth': 8, 'min_samples_split': 9}. Best is trial 3 with value: 0.9666666666666667.\n",
      "[I 2025-02-27 08:12:06,278] Trial 19 finished with value: 0.96 and parameters: {'n_estimators': 166, 'max_depth': 14, 'min_samples_split': 6}. Best is trial 3 with value: 0.9666666666666667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 34, 'max_depth': 9, 'min_samples_split': 9}\n",
      "Best Score: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Example dataset\n",
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Objective function that Optuna will optimize\n",
    "def objective(trial):\n",
    "\n",
    "    # Define hyperparameter search spaces (i.e. between 10-200, 5-30, 2-10)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 30)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "\n",
    "    # Create Random Forest model with the suggested hyperparameters\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split\n",
    "    )\n",
    "\n",
    "    # Perform cross validation and return mean accuracy score\n",
    "    # cv=3 means 3-fold cross validation\n",
    "    score = cross_val_score(model, X, y, cv=3, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "# Create an Optuna study object that maximizes the objective\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Run optimization for 20 trials\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(f\"Best Parameters: {study.best_params}\")\n",
    "print(f\"Best Score: {study.best_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (1700, 20) (1700,)\n",
      "Eval shape: (300, 20) (300,)\n",
      "Logistic Regression: Accuracy = 0.9067, F1 = 0.9041\n",
      "Random Forest:       Accuracy = 0.9267, F1 = 0.9262\n",
      "Gradient Boosting:   Accuracy = 0.9533, F1 = 0.9514\n",
      "\n",
      "The best model based on the eval set is: Gradient Boosting with F1 = 0.9514\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "RANDOM_STATE=42\n",
    "\n",
    "# 1. Generate a synthetic classification dataset\n",
    "X, y = make_classification(n_samples=2000, n_features=20, n_informative=10,\n",
    "                           n_redundant=5, n_classes=2, random_state=RANDOM_STATE)\n",
    "\n",
    "# 2. Split into CV and eval sets (this would have been done earlier, such that eval set has not yet been used)\n",
    "X_cv, X_eval, y_cv, y_eval = train_test_split(X, y, test_size=0.15, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"Training shape:\", X_cv.shape, y_cv.shape)\n",
    "print(\"Eval shape:\", X_eval.shape, y_eval.shape)\n",
    "\n",
    "# 3. Define three different models with chosen hyperparameters\n",
    "# These hyperparameters are hypothetical \"good\" choices based on prior tuning on the CV data.\n",
    "\n",
    "model_logreg = LogisticRegression(C=0.5, solver='liblinear', random_state=RANDOM_STATE)\n",
    "model_rf = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=5, random_state=RANDOM_STATE)\n",
    "model_gb = GradientBoostingClassifier(n_estimators=150, learning_rate=0.1, max_depth=5, random_state=RANDOM_STATE)\n",
    "\n",
    "# 4. Train each model on the CV set\n",
    "model_logreg.fit(X_cv, y_cv)\n",
    "model_rf.fit(X_cv, y_cv)\n",
    "model_gb.fit(X_cv, y_cv)\n",
    "\n",
    "# 5. Evaluate on the eval set\n",
    "logreg_preds = model_logreg.predict(X_eval)\n",
    "rf_preds = model_rf.predict(X_eval)\n",
    "gb_preds = model_gb.predict(X_eval)\n",
    "\n",
    "# Choose a metric: let's use accuracy and also look at F1 score for more insight\n",
    "logreg_accuracy = accuracy_score(y_eval, logreg_preds)\n",
    "rf_accuracy = accuracy_score(y_eval, rf_preds)\n",
    "gb_accuracy = accuracy_score(y_eval, gb_preds)\n",
    "\n",
    "logreg_f1 = f1_score(y_eval, logreg_preds)\n",
    "rf_f1 = f1_score(y_eval, rf_preds)\n",
    "gb_f1 = f1_score(y_eval, gb_preds)\n",
    "\n",
    "# Print results\n",
    "print(\"Logistic Regression: Accuracy = {:.4f}, F1 = {:.4f}\".format(logreg_accuracy, logreg_f1))\n",
    "print(\"Random Forest:       Accuracy = {:.4f}, F1 = {:.4f}\".format(rf_accuracy, rf_f1))\n",
    "print(\"Gradient Boosting:   Accuracy = {:.4f}, F1 = {:.4f}\".format(gb_accuracy, gb_f1))\n",
    "\n",
    "# 6. Select the best model based on the evaluation set results\n",
    "# Let's prioritize F1 score (just as an example); we could choose accuracy or a combination of metrics.\n",
    "models = {\n",
    "    \"Logistic Regression\": (logreg_accuracy, logreg_f1),\n",
    "    \"Random Forest\": (rf_accuracy, rf_f1),\n",
    "    \"Gradient Boosting\": (gb_accuracy, gb_f1)\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_f1 = -1\n",
    "for name, (acc, f1) in models.items():\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_model = name\n",
    "\n",
    "print(\"\\nThe best model based on the eval set is: {} with F1 = {:.4f}\".format(best_model, best_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n",
      "AUC: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Load binary classification dataset\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create pipeline with preprocessing and model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42, max_depth=2))\n",
    "])\n",
    "\n",
    "# Train the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions and probabilities\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f\"AUC: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/pro/zazencodes-courses/ai-engineer-roadmap/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1682 - loss: 2.2537 - val_accuracy: 0.6429 - val_loss: 1.8672\n",
      "Epoch 2/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5470 - loss: 1.7558 - val_accuracy: 0.8135 - val_loss: 1.1754\n",
      "Epoch 3/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6917 - loss: 1.1537 - val_accuracy: 0.8492 - val_loss: 0.6781\n",
      "Epoch 4/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8122 - loss: 0.6883 - val_accuracy: 0.8929 - val_loss: 0.4659\n",
      "Epoch 5/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8574 - loss: 0.5049 - val_accuracy: 0.9087 - val_loss: 0.3676\n",
      "Epoch 6/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.3974 - val_accuracy: 0.9246 - val_loss: 0.2935\n",
      "Epoch 7/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 0.3478 - val_accuracy: 0.9087 - val_loss: 0.2755\n",
      "Epoch 8/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9283 - loss: 0.3010 - val_accuracy: 0.9286 - val_loss: 0.2362\n",
      "Epoch 9/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.2575 - val_accuracy: 0.9325 - val_loss: 0.2304\n",
      "Epoch 10/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9355 - loss: 0.2302 - val_accuracy: 0.9286 - val_loss: 0.2173\n",
      "Epoch 11/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.2233 - val_accuracy: 0.9405 - val_loss: 0.1984\n",
      "Epoch 12/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1861 - val_accuracy: 0.9365 - val_loss: 0.2084\n",
      "Epoch 13/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9307 - loss: 0.2078 - val_accuracy: 0.9325 - val_loss: 0.2064\n",
      "Epoch 14/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.1373 - val_accuracy: 0.9405 - val_loss: 0.1744\n",
      "Epoch 15/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9507 - loss: 0.1529 - val_accuracy: 0.9484 - val_loss: 0.1744\n",
      "Epoch 16/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9758 - loss: 0.1250 - val_accuracy: 0.9325 - val_loss: 0.1660\n",
      "Epoch 17/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9643 - loss: 0.1255 - val_accuracy: 0.9484 - val_loss: 0.1733\n",
      "Epoch 18/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9739 - loss: 0.1101 - val_accuracy: 0.9405 - val_loss: 0.1609\n",
      "Epoch 19/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9566 - loss: 0.1358 - val_accuracy: 0.9405 - val_loss: 0.1778\n",
      "Epoch 20/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9687 - loss: 0.1101 - val_accuracy: 0.9444 - val_loss: 0.1759\n",
      "Epoch 21/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9801 - loss: 0.0828 - val_accuracy: 0.9365 - val_loss: 0.1659\n",
      "Epoch 22/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9808 - loss: 0.0813 - val_accuracy: 0.9405 - val_loss: 0.1542\n",
      "Epoch 23/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9795 - loss: 0.0831 - val_accuracy: 0.9365 - val_loss: 0.1659\n",
      "Epoch 24/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.0957 - val_accuracy: 0.9444 - val_loss: 0.1666\n",
      "Epoch 25/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.0865 - val_accuracy: 0.9444 - val_loss: 0.1542\n",
      "Epoch 26/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0580 - val_accuracy: 0.9484 - val_loss: 0.1547\n",
      "Epoch 27/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9807 - loss: 0.0783 - val_accuracy: 0.9484 - val_loss: 0.1460\n",
      "Epoch 28/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9803 - loss: 0.0730 - val_accuracy: 0.9444 - val_loss: 0.1516\n",
      "Epoch 29/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0628 - val_accuracy: 0.9524 - val_loss: 0.1634\n",
      "Epoch 30/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9898 - loss: 0.0558 - val_accuracy: 0.9405 - val_loss: 0.1553\n",
      "Epoch 31/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0554 - val_accuracy: 0.9524 - val_loss: 0.1456\n",
      "Epoch 32/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9730 - loss: 0.0767 - val_accuracy: 0.9405 - val_loss: 0.1450\n",
      "Epoch 33/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 0.0442 - val_accuracy: 0.9524 - val_loss: 0.1568\n",
      "Epoch 34/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0439 - val_accuracy: 0.9484 - val_loss: 0.1467\n",
      "Epoch 35/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9817 - loss: 0.0637 - val_accuracy: 0.9444 - val_loss: 0.1360\n",
      "Epoch 36/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0539 - val_accuracy: 0.9524 - val_loss: 0.1422\n",
      "Epoch 37/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0607 - val_accuracy: 0.9444 - val_loss: 0.1424\n",
      "Epoch 38/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0592 - val_accuracy: 0.9603 - val_loss: 0.1297\n",
      "Epoch 39/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0507 - val_accuracy: 0.9603 - val_loss: 0.1287\n",
      "Epoch 40/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0544 - val_accuracy: 0.9524 - val_loss: 0.1284\n",
      "Epoch 41/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0479 - val_accuracy: 0.9524 - val_loss: 0.1276\n",
      "Epoch 42/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0448 - val_accuracy: 0.9484 - val_loss: 0.1352\n",
      "Epoch 43/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9946 - loss: 0.0397 - val_accuracy: 0.9405 - val_loss: 0.1446\n",
      "Epoch 44/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0336 - val_accuracy: 0.9524 - val_loss: 0.1386\n",
      "Epoch 45/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0334 - val_accuracy: 0.9563 - val_loss: 0.1220\n",
      "Epoch 46/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0327 - val_accuracy: 0.9484 - val_loss: 0.1476\n",
      "Epoch 47/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0329 - val_accuracy: 0.9603 - val_loss: 0.1332\n",
      "Epoch 48/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0312 - val_accuracy: 0.9484 - val_loss: 0.1351\n",
      "Epoch 49/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0214 - val_accuracy: 0.9444 - val_loss: 0.1378\n",
      "Epoch 50/50\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0376 - val_accuracy: 0.9603 - val_loss: 0.1247\n",
      "Test accuracy: 0.976\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Sample prediction classes:\n",
      "Prediction: 6, Actual: 6\n",
      "Prediction: 9, Actual: 9\n",
      "Prediction: 3, Actual: 3\n",
      "Prediction: 7, Actual: 7\n",
      "Prediction: 2, Actual: 2\n",
      "Prediction: 1, Actual: 1\n",
      "Prediction: 5, Actual: 5\n",
      "Prediction: 2, Actual: 2\n",
      "Prediction: 5, Actual: 5\n",
      "Prediction: 2, Actual: 2\n",
      "Prediction: 1, Actual: 1\n",
      "Prediction: 9, Actual: 9\n",
      "Prediction: 4, Actual: 4\n",
      "Prediction: 0, Actual: 0\n",
      "Prediction: 4, Actual: 4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess data\n",
    "digits = load_digits()\n",
    "X = digits.data.astype('float32') / 16.0  # Normalize data\n",
    "y = tf.keras.utils.to_categorical(digits.target, 10)  # One-hot encode labels\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(64,)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test accuracy: {test_accuracy:.3f}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "print(\"Sample prediction classes:\")\n",
    "for i in range(15):\n",
    "    print(f\"Prediction: {predicted_classes[i]}, Actual: {np.argmax(y_test[i])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 2.2110, Train Acc: 0.2876, Val Loss: 2.0519, Val Acc: 0.5079\n",
      "Epoch 6/50, Train Loss: 0.4684, Train Acc: 0.8726, Val Loss: 0.4079, Val Acc: 0.9008\n",
      "Epoch 11/50, Train Loss: 0.2408, Train Acc: 0.9284, Val Loss: 0.2429, Val Acc: 0.9444\n",
      "Epoch 16/50, Train Loss: 0.1555, Train Acc: 0.9602, Val Loss: 0.2006, Val Acc: 0.9325\n",
      "Epoch 21/50, Train Loss: 0.1237, Train Acc: 0.9632, Val Loss: 0.1611, Val Acc: 0.9524\n",
      "Epoch 26/50, Train Loss: 0.0977, Train Acc: 0.9721, Val Loss: 0.1425, Val Acc: 0.9484\n",
      "Epoch 31/50, Train Loss: 0.0837, Train Acc: 0.9692, Val Loss: 0.1255, Val Acc: 0.9603\n",
      "Epoch 36/50, Train Loss: 0.0597, Train Acc: 0.9821, Val Loss: 0.1124, Val Acc: 0.9643\n",
      "Epoch 41/50, Train Loss: 0.0480, Train Acc: 0.9881, Val Loss: 0.1341, Val Acc: 0.9563\n",
      "Epoch 46/50, Train Loss: 0.0397, Train Acc: 0.9891, Val Loss: 0.1160, Val Acc: 0.9643\n",
      "Epoch 50/50, Train Loss: 0.0339, Train Acc: 0.9920, Val Loss: 0.1333, Val Acc: 0.9484\n",
      "Test accuracy: 0.967\n",
      "Sample prediction classes:\n",
      "Prediction: 6, Actual: 6\n",
      "Prediction: 9, Actual: 9\n",
      "Prediction: 3, Actual: 3\n",
      "Prediction: 7, Actual: 7\n",
      "Prediction: 2, Actual: 2\n",
      "Prediction: 2, Actual: 1\n",
      "Prediction: 5, Actual: 5\n",
      "Prediction: 2, Actual: 2\n",
      "Prediction: 5, Actual: 5\n",
      "Prediction: 2, Actual: 2\n",
      "Prediction: 1, Actual: 1\n",
      "Prediction: 8, Actual: 9\n",
      "Prediction: 4, Actual: 4\n",
      "Prediction: 0, Actual: 0\n",
      "Prediction: 4, Actual: 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess data\n",
    "digits = load_digits()\n",
    "X = digits.data.astype('float32') / 16.0\n",
    "y = digits.target\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors and create datasets\n",
    "train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
    "test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.LongTensor(y_test))\n",
    "\n",
    "# Split training data for validation (20%)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_subset, val_subset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(64, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(64, 10)\n",
    ")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return running_loss/len(loader), correct/total\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return running_loss/len(loader), correct/total\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(50):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "    \n",
    "    if epoch % 5 == 0 or epoch == 49:  # Print only every 5 epochs to reduce verbosity\n",
    "        print(f'Epoch {epoch+1}/50, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
    "print(f'Test accuracy: {test_acc:.3f}')\n",
    "\n",
    "# Make predictions on test data\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Print sample predictions\n",
    "print(\"Sample prediction classes:\")\n",
    "for i in range(15):\n",
    "    print(f\"Prediction: {predictions[i]}, Actual: {true_labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/27 10:00:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logged with accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3)\n",
    "\n",
    "# Start an MLflow experiment\n",
    "with mlflow.start_run():\n",
    "    # Train a model\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Log metrics and model\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.sklearn.log_model(clf, \"model\")\n",
    "\n",
    "    print(f\"Model logged with accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Initialize a W&B run\n",
    "wandb.init(project=\"mlops-example\")\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return torch.softmax(self.fc2(x), dim=1)\n",
    "\n",
    "model = SimpleModel()\n",
    "\n",
    "# Log hyperparameters\n",
    "config = {\"learning_rate\": 0.001, \"epochs\": 5}\n",
    "wandb.config.update(config)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
